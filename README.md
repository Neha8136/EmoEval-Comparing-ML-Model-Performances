# EmoEval: Comparing ML Model Performances
                                                  Introduction 
This project develops an Electroencephalogram (EEG) Emotion Extractor, a system for detecting and interpreting human emotions from EEG signals. Using state-of-the-art EEG devices, brainwave data is recorded and processed with advanced signal processing techniques. Feature extraction methods identify patterns linked to emotional states.

Machine learning algorithms like support vector machines (SVM) and K-Nearest Neighbor (KNN) classify emotions such as positive, negative and neutral. Performance is evaluated using accuracy, precision, recall, and F1-score.

The project also integrates real-time emotion detection into applications for adaptive learning, mental health therapy, and responsive gaming. Ethical considerations regarding user privacy and data security are addressed.

      ![image](https://github.com/Neha8136/EmoEval_Comparing_ML_Model_Performances/assets/91106552/c9a1b9b4-841b-4e76-9491-06f73ed20097)


In summary, the EEG Emotion Extractor demonstrates the potential of using EEG signals for emotion recognition, enhancing human-computer interactions and emotional well-being through innovative technology. 
This project explores the detailed process of extracting emotions using EEG technology. It covers every step from inducing emotions and capturing brain signals to cleaning and analyzing the data to identify specific features and classify different emotional states. The insights from this research can significantly improve our understanding of how the brain processes emotions and enhance various applications that depend on accurate emotion recognition. 
                                Methodologies for Emotion Extraction
Understanding human emotions through EEG (Electroencephalography) involves a systematic approach integrating data collection, signal processing, and machine learning techniques. This section outlines the methodologies employed to  process, and analyze EEG data for emotion recognition.
Steps in Emotion Extraction Methodologies:
1. Data Collection and Preparation
2. Feature Extraction
3. Classification Techniques
4. Machine Learning Model Training


          Flowchart
   
          ![image](https://github.com/Neha8136/EmoEval_Comparing_ML_Model_Performances/assets/91106552/a8a2ce8f-51f5-4dcb-9da4-43c1700b4be1)

This flowchart depicts a process for classifying emotions based on EEG (electroencephalogram) recordings. Here's a detailed breakdown:
  A stimulus, such as a video or image, is presented to a subject. The subject's brain activity is recorded using EEG, capturing the electrical activity of the brain. The raw EEG data undergoes preprocessing to remove noise and artifacts, resulting in cleaner signals. Features are extracted from the preprocessed EEG signals. This involves analyzing different frequency bands across 32 channels.  The extracted features are processed over time, creating a series of time segments for analysis. The processed time series data is used to train a machine learning model. This model learns to classify emotions based on the features extracted from the EEG data. Once the model is trained, it can classify new EEG data into three emotional categories: positive, neutral, or negative.
The diagram illustrates the flow from stimulus presentation to emotion classification, emphasizing the sequential steps of EEG recording, signal preprocessing, feature extraction, time series processing, model training, and finally, emotion classification.


   




